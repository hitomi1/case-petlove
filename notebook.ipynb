{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descomentar essa linha abaixo case deseje fazer a instalação dos pacotes por aqui\n",
    "#!pip install pyspark numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, when, col, isnan, to_date, floor, datediff, current_date, round\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando a sessão do Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>case-petlove</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a9b69cca90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"case-petlove\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o arquivo CSV disponibilizado, mantendo o cabeçalho e inferindo um schema de acordo com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"initial_data/data-test-analytics.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando a leitura do arquivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso esteja rodando no VSCode use apenas \"df.show\" para melhor visualização do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " id                 | 8bf7960e-3b93-468... \n",
      " created_at         | 08/15/17 07:05 AM    \n",
      " updated_at         | 01/14/21 11:23 AM    \n",
      " deleted_at         | null                 \n",
      " name_hash          | 312d206168a318614... \n",
      " email_hash         | 83eb3aed9a44377df... \n",
      " address_hash       | 8b4bfaa0cbc41a16f... \n",
      " birth_date         | 07/10/74 12:00 AM    \n",
      " status             | active               \n",
      " version            | 2.31.7               \n",
      " city               |  Peixoto da Praia    \n",
      " state              | AM                   \n",
      " neighborhood       | Aparecida 7ª Seção   \n",
      " last_date_purchase | 01/14/21 11:23 AM    \n",
      " average_ticket     | 151.142941888541     \n",
      " items_quantity     | 10                   \n",
      " all_revenue        | 906.857651331245     \n",
      " all_orders         | 6                    \n",
      " recency            | 35                   \n",
      " marketing_source   | crm                  \n",
      "-RECORD 1----------------------------------\n",
      " id                 | a39535b5-4647-468... \n",
      " created_at         | 12/31/19 09:53 PM    \n",
      " updated_at         | 01/08/21 11:23 AM    \n",
      " deleted_at         | null                 \n",
      " name_hash          | de448fcb47d0d6a87... \n",
      " email_hash         | 72678bb35e2ac84ed... \n",
      " address_hash       | 22f1cfa1847f38da3... \n",
      " birth_date         | 07/06/40 12:00 AM    \n",
      " status             | paused               \n",
      " version            | 3.30.12              \n",
      " city               |  Fernandes           \n",
      " state              | RR                   \n",
      " neighborhood       | Santa Isabel         \n",
      " last_date_purchase | 01/08/21 11:23 AM    \n",
      " average_ticket     | 236.991789979188     \n",
      " items_quantity     | 4                    \n",
      " all_revenue        | 236.991789979188     \n",
      " all_orders         | 1                    \n",
      " recency            | 41                   \n",
      " marketing_source   | organic_search       \n",
      "-RECORD 2----------------------------------\n",
      " id                 | dc067cd2-c021-42b... \n",
      " created_at         | 03/07/19 11:46 PM    \n",
      " updated_at         | 01/07/21 11:23 AM    \n",
      " deleted_at         | null                 \n",
      " name_hash          | cb09e447ddc382833... \n",
      " email_hash         | 668f4ee9add29c7bd... \n",
      " address_hash       | 6cb47446a086ee648... \n",
      " birth_date         | 03/18/63 12:00 AM    \n",
      " status             | active               \n",
      " version            | 3.28.9               \n",
      " city               |  Lopes               \n",
      " state              | RR                   \n",
      " neighborhood       | Estrela              \n",
      " last_date_purchase | 01/07/21 11:23 AM    \n",
      " average_ticket     | 211.955597446163     \n",
      " items_quantity     | 13                   \n",
      " all_revenue        | 2331.5115719078      \n",
      " all_orders         | 11                   \n",
      " recency            | 42                   \n",
      " marketing_source   | organic_search       \n",
      "-RECORD 3----------------------------------\n",
      " id                 | b5e4caeb-3a9b-49e... \n",
      " created_at         | 07/21/18 10:17 AM    \n",
      " updated_at         | 01/10/21 11:23 AM    \n",
      " deleted_at         | null                 \n",
      " name_hash          | 52593437a405b11b3... \n",
      " email_hash         | d3fb45188d95c8d7c... \n",
      " address_hash       | 0a6f0c54db1e6f193... \n",
      " birth_date         | 11/21/80 12:00 AM    \n",
      " status             | active               \n",
      " version            | 3.34.3               \n",
      " city               |  Campos do Campo     \n",
      " state              | PE                   \n",
      " neighborhood       | Confisco             \n",
      " last_date_purchase | 01/10/21 11:23 AM    \n",
      " average_ticket     | 204.113226530216     \n",
      " items_quantity     | 8                    \n",
      " all_revenue        | 1224.67935918129     \n",
      " all_orders         | 6                    \n",
      " recency            | 39                   \n",
      " marketing_source   | organic_search       \n",
      "-RECORD 4----------------------------------\n",
      " id                 | d4ff61fc-f008-4e1... \n",
      " created_at         | 06/08/18 12:09 PM    \n",
      " updated_at         | 01/18/21 11:23 AM    \n",
      " deleted_at         | null                 \n",
      " name_hash          | dbda4b778a966c219... \n",
      " email_hash         | a0f76bc49b4c43327... \n",
      " address_hash       | 143b9f169b4fa1692... \n",
      " birth_date         | 07/07/59 12:00 AM    \n",
      " status             | active               \n",
      " version            | 3.19.8               \n",
      " city               |  das Neves           \n",
      " state              | RJ                   \n",
      " neighborhood       | Vila Suzana Segun... \n",
      " last_date_purchase | 01/18/21 11:23 AM    \n",
      " average_ticket     | 252.94099747406      \n",
      " items_quantity     | 9                    \n",
      " all_revenue        | 2023.52797979248     \n",
      " all_orders         | 8                    \n",
      " recency            | 31                   \n",
      " marketing_source   | crm                  \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=5, truncate=True, vertical=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando se há valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " id                 | 0    \n",
      " created_at         | 0    \n",
      " updated_at         | 0    \n",
      " deleted_at         | 9495 \n",
      " name_hash          | 0    \n",
      " email_hash         | 0    \n",
      " address_hash       | 0    \n",
      " birth_date         | 0    \n",
      " status             | 0    \n",
      " version            | 0    \n",
      " city               | 0    \n",
      " state              | 0    \n",
      " neighborhood       | 0    \n",
      " last_date_purchase | 0    \n",
      " average_ticket     | 0    \n",
      " items_quantity     | 0    \n",
      " all_revenue        | 0    \n",
      " all_orders         | 0    \n",
      " recency            | 0    \n",
      " marketing_source   | 0    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    [count\n",
    "        (when\n",
    "            (col(c).contains('None') | \\\n",
    "            col(c).contains('Null') | \\\n",
    "            (col(c) == '') | \\\n",
    "            col(c).isNull() | \\\n",
    "            isnan(c), c)\n",
    "        ).alias(c)\n",
    "    for c in df.columns]).show(n=5, truncate=False, vertical=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores nulos apresentados não atrapalham nossa análise, pois representam a data de quando o \"id\" foi deletado/cancelou sua assinatura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando as colunas que não farão parte da análise, visto que não possuem dados/estão criptografados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('name_hash', 'email_hash', 'address_hash')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando o schema atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- deleted_at: string (nullable = true)\n",
      " |-- birth_date: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- last_date_purchase: string (nullable = true)\n",
      " |-- average_ticket: double (nullable = true)\n",
      " |-- items_quantity: integer (nullable = true)\n",
      " |-- all_revenue: double (nullable = true)\n",
      " |-- all_orders: integer (nullable = true)\n",
      " |-- recency: integer (nullable = true)\n",
      " |-- marketing_source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando os campos de acordo com o formato correto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferindo o tipo \"date\" para as colunas de datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('created_at', to_date(df['created_at'], 'MM/dd/yy hh:mm a')) \\\n",
    "       .withColumn('updated_at', to_date(df['updated_at'], 'MM/dd/yy hh:mm a')) \\\n",
    "       .withColumn('deleted_at', to_date(df['deleted_at'], 'MM/dd/yy hh:mm a')) \\\n",
    "       .withColumn('birth_date', to_date(df['birth_date'], 'MM/dd/yy hh:mm a')-36525) \\\n",
    "       .withColumn('last_date_purchase', to_date(df['last_date_purchase'], 'MM/dd/yy hh:mm a')) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferindo o tipo \"float\" para as colunas de valor monetário (uma boa prática é se usar double ou uma biblioteca específica para isso, porém os dados estavam quebrados e com muitas casas decimais, tomei a liberdade de usar uma aproximação com float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('average_ticket', round(df[\"average_ticket\"].cast(FloatType()),2))  \\\n",
    "       .withColumn('all_revenue', round(df[\"all_revenue\"].cast(FloatType()), 2) ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma nova coluna \"age\", facilitando o trabalho com a coluna birth_date, em análises pontuais essa é uma prática ok, mas não deve ser usada para dashboards iterativas, nesse caso deve-se usar um campo cálculado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('age',floor(datediff(current_date(), to_date(col('birth_date'), 'M/d/yyyy'))/365.24).cast('integer'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checando nosso schema atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- created_at: date (nullable = true)\n",
      " |-- updated_at: date (nullable = true)\n",
      " |-- deleted_at: date (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- last_date_purchase: date (nullable = true)\n",
      " |-- average_ticket: float (nullable = true)\n",
      " |-- items_quantity: integer (nullable = true)\n",
      " |-- all_revenue: float (nullable = true)\n",
      " |-- all_orders: integer (nullable = true)\n",
      " |-- recency: integer (nullable = true)\n",
      " |-- marketing_source: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ao final da limpeza e criação de novas colunas obtemos o seguinte esquema com as váriaveis sendo definidas em:\n",
    "\n",
    "1.  Numéricas\n",
    "\t1. Discreta\n",
    "\t\t1. created_at\n",
    "\t\t2. updated_at\n",
    "\t\t3. deleted_at\n",
    "\t\t4. birth_date\n",
    "\t\t5. last_date_purchase\n",
    "\t\t6. items_quantity\n",
    "\t\t7. recency\n",
    "\t\t8. age\n",
    "\t2.  Contínua\n",
    "\t\t1. average_ticket\n",
    "\t\t2. all_revenue\n",
    "\t\t3. all_orders\n",
    "2. Categoricas\n",
    "\t1. ID\n",
    "\t2. status: 3 valores distintos\n",
    "\t3. version:\n",
    "\t4. city\n",
    "\t5. state\n",
    "\t6. neighborhood\n",
    "\t7. marketing_source\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando o shape do nosso DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape: 10000 x 18\n"
     ]
    }
   ],
   "source": [
    "print(f'DF Shape: {df.count()} x {len(df.columns)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando o dataframe para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv(\"data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso fizemos a conversão para pandas \"toPandas()\", pois o Spark trabalho com o dataframe de forma distribuida, necessitando de outras bibliotecas e configurações para poder exportar o CSV em um único arquivo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
